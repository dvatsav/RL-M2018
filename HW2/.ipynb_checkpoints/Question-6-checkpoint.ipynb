{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 1\n",
    "n = 4\n",
    "action_names = {'-1' : 'g', '0' : 'l', '1' : 'u', '2' : 'r', '3' : 'd'}\n",
    "actions = [(0, -1), (-1, 0), (0, 1), (1,0)]\n",
    "values = np.zeros((n, n))\n",
    "policy = np.zeros((n, n), dtype=int)\n",
    "policy[0][0] = -1\n",
    "policy[n-1][n-1] = -1\n",
    "policy_multiple = {(0,0):[], (n-1,n-1):[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Policy Iteration Method\n",
    "\"\"\"\n",
    "\n",
    "def get_state(i, j, action):\n",
    "    if i + action[0] < 0 or i + action[0] >= n or j + action[1] < 0 or j + action[1] >= n: # Check bounds after checking for A and B\n",
    "        x,y = i,j\n",
    "    else:\n",
    "        x,y = i + action[0], j + action[1]\n",
    "    return (x,y)\n",
    "\n",
    "def evaluate_policy():\n",
    "    \n",
    "    theta = 2\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                old_value_s = values[i, j]\n",
    "                if policy[i, j] != -1:\n",
    "                    action = actions[policy[i,j]]\n",
    "                    reward = -1.0\n",
    "                    x, y = get_state(i, j, action)\n",
    "                    values[i, j] = (reward + discount_factor * (values[x, y]))\n",
    "                \n",
    "                delta = max(delta, np.abs(old_value_s - values[i, j]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return values\n",
    "        \n",
    "def improve_policy():\n",
    "    stable = True\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            returns = np.zeros(len(actions))\n",
    "            if policy[i, j] != -1:\n",
    "                old_policy = policy[i, j]\n",
    "                max_return = -np.inf\n",
    "                best_action = actions[old_policy]\n",
    "                for ind, action in enumerate(actions):\n",
    "                    reward = -1.0\n",
    "                    x, y = get_state(i, j, action)\n",
    "                    expected_return = (reward + discount_factor * (values[x, y]))\n",
    "                    returns[ind] = expected_return\n",
    "\n",
    "                policy[i, j] = np.argmax(returns)\n",
    "                sorted_returns = np.argsort(returns)\n",
    "                best_return = np.max(returns)\n",
    "                best_actions = sorted_returns[len(actions) - (list(returns)).count(best_return):]\n",
    "                best_actions = list(map(lambda x: action_names[str(x)], best_actions))\n",
    "                policy_multiple[(i, j)] = best_actions\n",
    "\n",
    "                if policy[i, j] != old_policy:\n",
    "                    stable = False\n",
    "    return stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "-----------------------------\n",
      "Values\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-2. -3. -4. -5.]\n",
      " [-2. -3. -4. -5.]\n",
      " [-2. -3. -4.  0.]]\n",
      "-----------------------------\n",
      "Policy\n",
      "[] ['l'] ['l'] ['l'] \n",
      "['u'] ['u'] ['u'] ['u'] \n",
      "['l', 'u', 'd'] ['l'] ['l'] ['d'] \n",
      "['l', 'u', 'd'] ['l'] ['r'] [] \n",
      "-----------------------------\n",
      "Iteration 2\n",
      "-----------------------------\n",
      "Values\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -4.]\n",
      " [-4. -5. -6. -1.]\n",
      " [-4. -5. -1.  0.]]\n",
      "-----------------------------\n",
      "Policy\n",
      "[] ['l'] ['l'] ['l'] \n",
      "['u'] ['l', 'u'] ['l', 'u'] ['d'] \n",
      "['u'] ['u'] ['r', 'd'] ['d'] \n",
      "['l', 'u', 'd'] ['r'] ['r'] [] \n",
      "-----------------------------\n",
      "Iteration 3\n",
      "-----------------------------\n",
      "Values\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-6. -2. -1.  0.]]\n",
      "-----------------------------\n",
      "Policy\n",
      "[] ['l'] ['l'] ['l', 'd'] \n",
      "['u'] ['l', 'u'] ['l', 'u', 'r', 'd'] ['d'] \n",
      "['u'] ['l', 'u', 'r', 'd'] ['r', 'd'] ['d'] \n",
      "['u', 'r'] ['r'] ['r'] [] \n",
      "-----------------------------\n",
      "Iteration 4\n",
      "-----------------------------\n",
      "Values\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "-----------------------------\n",
      "Policy\n",
      "[] ['l'] ['l'] ['l', 'd'] \n",
      "['u'] ['l', 'u'] ['l', 'u', 'r', 'd'] ['d'] \n",
      "['u'] ['l', 'u', 'r', 'd'] ['r', 'd'] ['d'] \n",
      "['u', 'r'] ['r'] ['r'] [] \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "while True:\n",
    "    it += 1\n",
    "    values = evaluate_policy()\n",
    "    stable = improve_policy()\n",
    "    print (\"Iteration\", it)\n",
    "    print (\"-----------------------------\")\n",
    "    print (\"Values\")\n",
    "    print (values)\n",
    "    print (\"-----------------------------\")\n",
    "    print (\"Policy\")\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            print (policy_multiple[(i, j)], end = \" \")\n",
    "        print (\"\")\n",
    "    print (\"-----------------------------\")\n",
    "    if stable:\n",
    "       break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -2., -3.],\n",
       "       [-1., -2., -3., -2.],\n",
       "       [-2., -3., -2., -1.],\n",
       "       [-3., -2., -1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] ['l'] ['l'] ['l', 'd'] \n",
      "['u'] ['l', 'u'] ['l', 'u', 'r', 'd'] ['d'] \n",
      "['u'] ['l', 'u', 'r', 'd'] ['r', 'd'] ['d'] \n",
      "['u', 'r'] ['r'] ['r'] [] \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "* Print Optimal Policy\n",
    "\"\"\"\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print (policy_multiple[(i, j)], end = \" \")\n",
    "    print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* Value Iteration\n",
    "\"\"\"\n",
    "\n",
    "values = np.zeros((n, n))\n",
    "policy = np.zeros((n, n), dtype=int)\n",
    "policy[0][0] = -1\n",
    "policy[n-1][n-1] = -1\n",
    "policy_multiple = {(0,0):[], (n-1,n-1):[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "---------------------------\n",
      "Delta - 1.0\n",
      "Values\n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1.  0.]]\n",
      "---------------------------\n",
      "Policy\n",
      "[] ['l', 'u', 'r', 'd'] ['u', 'r', 'd'] ['u', 'r', 'd'] \n",
      "['l', 'u', 'r', 'd'] ['r', 'd'] ['r', 'd'] ['r', 'd'] \n",
      "['l', 'r', 'd'] ['r', 'd'] ['r', 'd'] ['r', 'd'] \n",
      "['l', 'r', 'd'] ['r', 'd'] ['r', 'd'] [] \n",
      "---------------------------\n",
      "Iteration 2\n",
      "---------------------------\n",
      "Delta - 1.0\n",
      "Values\n",
      "[[ 0. -1. -2. -2.]\n",
      " [-1. -2. -2. -2.]\n",
      " [-2. -2. -2. -1.]\n",
      " [-2. -2. -1.  0.]]\n",
      "---------------------------\n",
      "Policy\n",
      "[] ['l'] ['l', 'u', 'r', 'd'] ['u', 'r', 'd'] \n",
      "['u'] ['l', 'u', 'r', 'd'] ['r', 'd'] ['r', 'd'] \n",
      "['l', 'u', 'r', 'd'] ['r', 'd'] ['r', 'd'] ['d'] \n",
      "['l', 'r', 'd'] ['r', 'd'] ['r'] [] \n",
      "---------------------------\n",
      "Iteration 3\n",
      "---------------------------\n",
      "Delta - 1.0\n",
      "Values\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "---------------------------\n",
      "Policy\n",
      "[] ['l'] ['l'] ['l', 'u', 'r', 'd'] \n",
      "['u'] ['l', 'u'] ['l', 'u', 'r', 'd'] ['d'] \n",
      "['u'] ['l', 'u', 'r', 'd'] ['r', 'd'] ['d'] \n",
      "['l', 'u', 'r', 'd'] ['r'] ['r'] [] \n",
      "---------------------------\n",
      "Iteration 4\n",
      "---------------------------\n",
      "Delta - 0\n",
      "Values\n",
      "[[ 0. -1. -2. -3.]\n",
      " [-1. -2. -3. -2.]\n",
      " [-2. -3. -2. -1.]\n",
      " [-3. -2. -1.  0.]]\n",
      "---------------------------\n",
      "Policy\n",
      "[] ['l'] ['l'] ['l', 'd'] \n",
      "['u'] ['l', 'u'] ['l', 'u', 'r', 'd'] ['d'] \n",
      "['u'] ['l', 'u', 'r', 'd'] ['r', 'd'] ['d'] \n",
      "['u', 'r'] ['r'] ['r'] [] \n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "theta = 1e-4\n",
    "it = 0\n",
    "while True:\n",
    "    delta = 0\n",
    "    it += 1\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            returns = np.zeros(len(actions))\n",
    "            if policy[i, j] != -1:\n",
    "                old_value = values[i, j]\n",
    "                max_return = -np.inf\n",
    "                best_action = actions[policy[i, j]]\n",
    "                \n",
    "                for ind, action in enumerate(actions):\n",
    "                    reward = -1.0\n",
    "                    if i + action[0] < 0 or i + action[0] >= n or j + action[1] < 0 or j + action[1] >= n: # Check bounds after checking for A and B\n",
    "                        x,y = i,j\n",
    "                    else:\n",
    "                        x,y = i + action[0], j + action[1]\n",
    "                    expected_return = (reward + discount_factor * (values[x, y]))\n",
    "                    returns[ind] = expected_return\n",
    "                        \n",
    "                values[i, j] = np.max(returns)\n",
    "                policy[i, j] = np.argmax(returns)\n",
    "                sorted_returns = np.argsort(returns)\n",
    "                best_return = np.max(returns)\n",
    "                best_actions = sorted_returns[len(actions) - (list(returns)).count(best_return):]\n",
    "                best_actions = list(map(lambda x: action_names[str(x)], best_actions))\n",
    "                policy_multiple[(i, j)] = best_actions\n",
    "                \n",
    "                delta = max(delta, np.abs(old_value - values[i, j]))\n",
    "    print (\"Iteration\", it)\n",
    "    print (\"---------------------------\")\n",
    "    print (\"Delta -\", delta)\n",
    "    print (\"Values\")\n",
    "    print (values)\n",
    "    print (\"---------------------------\")\n",
    "    print (\"Policy\")\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            print (policy_multiple[(i, j)], end = \" \")\n",
    "        print (\"\")\n",
    "    print (\"---------------------------\")\n",
    "    if delta < theta:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1., -2., -3.],\n",
       "       [-1., -2., -3., -2.],\n",
       "       [-2., -3., -2., -1.],\n",
       "       [-3., -2., -1.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "* Optimal Values\n",
    "\"\"\"\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] ['l'] ['l'] ['l', 'd'] \n",
      "['u'] ['l', 'u'] ['l', 'u', 'r', 'd'] ['d'] \n",
      "['u'] ['l', 'u', 'r', 'd'] ['r', 'd'] ['d'] \n",
      "['u', 'r'] ['r'] ['r'] [] \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "* Optimal Policy\n",
    "\"\"\"\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print (policy_multiple[(i, j)], end = \" \")\n",
    "    print (\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
